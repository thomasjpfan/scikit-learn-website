

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
   <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.cross_decomposition.PLSCanonical &mdash; scikit-learn 0.22.dev0 documentation</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSCanonical.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" /> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Docs</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
            <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/basic/tutorial.html">Quick Start</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glossary</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Development</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Related packages</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Roadmap</a>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">About us</a>
            <div class="dropdown-divider"></div>
            <a class="sk-nav-dropdown-item dropdown-item" href="../../documentation.html">Documentation</a>
          </div>
        </li>
      </ul>
      <div class="sk-search-form">
          <div class="gcse-search" id="cse" data-linktarget="_parent"></div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div><div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="sklearn.cross_decomposition.CCA.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.cross_decomposition.CCA">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="API Reference">Up</a>
              <a href="sklearn.cross_decomposition.PLSRegression.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.cross_decomposition.PLSRegression">Next</a>
          </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.22.dev0</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Other versions</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Please <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cite us</string></a> if you use the software.
          </p>
        </div>
        <div class="sk-local-toc">
          <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cross_decomposition</span></code>.PLSCanonical</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-cross-decomposition-plscanonical">Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.cross_decomposition.PLSCanonical</span></code></a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper" >
      <div class="sk-page-content container-fluid body pl-md-4 px-lg-5" role="main">
        
  <div class="section" id="sklearn-cross-decomposition-plscanonical">
<h1><a class="reference internal" href="../classes.html#module-sklearn.cross_decomposition" title="sklearn.cross_decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cross_decomposition</span></code></a>.PLSCanonical<a class="headerlink" href="#sklearn-cross-decomposition-plscanonical" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.cross_decomposition.PLSCanonical">
<em class="property">class </em><code class="sig-prename descclassname">sklearn.cross_decomposition.</code><code class="sig-name descname">PLSCanonical</code><span class="sig-paren">(</span><em class="sig-param">n_components=2</em>, <em class="sig-param">scale=True</em>, <em class="sig-param">algorithm='nipals'</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L609"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical" title="Permalink to this definition">¶</a></dt>
<dd><p>PLSCanonical implements the 2 blocks canonical PLS of the original Wold
algorithm [Tenenhaus 1998] p.204, referred as PLS-C2A in [Wegelin 2000].</p>
<p>This class inherits from PLS with mode=”A” and deflation_mode=”canonical”,
norm_y_weights=True and algorithm=”nipals”, but svd should provide similar
results up to numerical errors.</p>
<p>Read more in the <a class="reference internal" href="../cross_decomposition.html#cross-decomposition"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_components</strong><span class="classifier">int, (default 2).</span></dt><dd><p>Number of components to keep</p>
</dd>
<dt><strong>scale</strong><span class="classifier">boolean, (default True)</span></dt><dd><p>Option to scale data</p>
</dd>
<dt><strong>algorithm</strong><span class="classifier">string, “nipals” or “svd”</span></dt><dd><p>The algorithm used to estimate the weights. It will be called
n_components times, i.e. once for each iteration of the outer loop.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">an integer, (default 500)</span></dt><dd><p>the maximum number of iterations of the NIPALS inner loop (used
only if algorithm=”nipals”)</p>
</dd>
<dt><strong>tol</strong><span class="classifier">non-negative real, default 1e-06</span></dt><dd><p>the tolerance used in the iterative algorithm</p>
</dd>
<dt><strong>copy</strong><span class="classifier">boolean, default True</span></dt><dd><p>Whether the deflation should be done on a copy. Let the default
value to True unless you don’t care about side effect</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>x_weights_</strong><span class="classifier">array, shape = [p, n_components]</span></dt><dd><p>X block weights vectors.</p>
</dd>
<dt><strong>y_weights_</strong><span class="classifier">array, shape = [q, n_components]</span></dt><dd><p>Y block weights vectors.</p>
</dd>
<dt><strong>x_loadings_</strong><span class="classifier">array, shape = [p, n_components]</span></dt><dd><p>X block loadings vectors.</p>
</dd>
<dt><strong>y_loadings_</strong><span class="classifier">array, shape = [q, n_components]</span></dt><dd><p>Y block loadings vectors.</p>
</dd>
<dt><strong>x_scores_</strong><span class="classifier">array, shape = [n_samples, n_components]</span></dt><dd><p>X scores.</p>
</dd>
<dt><strong>y_scores_</strong><span class="classifier">array, shape = [n_samples, n_components]</span></dt><dd><p>Y scores.</p>
</dd>
<dt><strong>x_rotations_</strong><span class="classifier">array, shape = [p, n_components]</span></dt><dd><p>X block to latents rotations.</p>
</dd>
<dt><strong>y_rotations_</strong><span class="classifier">array, shape = [q, n_components]</span></dt><dd><p>Y block to latents rotations.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">array-like</span></dt><dd><p>Number of iterations of the NIPALS inner loop for each
component. Not useful if the algorithm provided is “svd”.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.cross_decomposition.CCA.html#sklearn.cross_decomposition.CCA" title="sklearn.cross_decomposition.CCA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CCA</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="sklearn.cross_decomposition.PLSSVD.html#sklearn.cross_decomposition.PLSSVD" title="sklearn.cross_decomposition.PLSSVD"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PLSSVD</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Matrices:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span><span class="p">:</span> <span class="n">x_scores_</span>
<span class="n">U</span><span class="p">:</span> <span class="n">y_scores_</span>
<span class="n">W</span><span class="p">:</span> <span class="n">x_weights_</span>
<span class="n">C</span><span class="p">:</span> <span class="n">y_weights_</span>
<span class="n">P</span><span class="p">:</span> <span class="n">x_loadings_</span>
<span class="n">Q</span><span class="p">:</span> <span class="n">y_loadings__</span>
</pre></div>
</div>
<p>Are computed such that:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">T</span> <span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Err</span> <span class="ow">and</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">U</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Err</span>
<span class="n">T</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xk</span> <span class="n">W</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">U</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">Yk</span> <span class="n">C</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_components</span><span class="p">)</span>
<span class="n">x_rotations_</span> <span class="o">=</span> <span class="n">W</span> <span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">T</span> <span class="n">W</span><span class="p">)</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_rotations_</span> <span class="o">=</span> <span class="n">C</span> <span class="p">(</span><span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="n">C</span><span class="p">)</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>where Xk and Yk are residual matrices at iteration k.</p>
<p><a class="reference external" href="http://www.eigenvector.com/Docs/Wise_pls_properties.pdf">Slides explaining PLS</a></p>
<p>For each component k, find weights u, v that optimize:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>max corr(Xk u, Yk v) * std(Xk u) std(Yk u), such that ``|u| = |v| = 1``
</pre></div>
</div>
<p>Note that it maximizes both the correlations between the scores and the
intra-block variances.</p>
<p>The residual matrix of X (Xk+1) block is obtained by the deflation on the
current X score: x_score.</p>
<p>The residual matrix of Y (Yk+1) block is obtained by deflation on the
current Y score. This performs a canonical symmetric version of the PLS
regression. But slightly different than the CCA. This is mostly used
for modeling.</p>
<p>This implementation provides the same results that the “plspm” package
provided in the R language (R-project), using the function plsca(X, Y).
Results are equal or collinear with the function
<code class="docutils literal notranslate"><span class="pre">pls(...,</span> <span class="pre">mode</span> <span class="pre">=</span> <span class="pre">&quot;canonical&quot;)</span></code> of the “mixOmics” package. The difference
relies in the fact that mixOmics implementation does not exactly implement
the Wold algorithm since it does not normalize y_weights to one.</p>
<p class="rubric">References</p>
<p>Jacob A. Wegelin. A survey of Partial Least Squares (PLS) methods, with
emphasis on the two-block case. Technical Report 371, Department of
Statistics, University of Washington, Seattle, 2000.</p>
<p>Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris:
Editions Technic.</p>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cross_decomposition</span> <span class="k">import</span> <span class="n">PLSCanonical</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">5.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.2</span><span class="p">,</span> <span class="mf">5.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">11.9</span><span class="p">,</span> <span class="mf">12.3</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plsca</span> <span class="o">=</span> <span class="n">PLSCanonical</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plsca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="go">PLSCanonical()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_c</span><span class="p">,</span> <span class="n">Y_c</span> <span class="o">=</span> <span class="n">plsca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.fit" title="sklearn.cross_decomposition.PLSCanonical.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self, X, Y)</p></td>
<td><p>Fit model to data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.fit_transform" title="sklearn.cross_decomposition.PLSCanonical.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(self, X[, y])</p></td>
<td><p>Learn and apply the dimension reduction on the train data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.get_params" title="sklearn.cross_decomposition.PLSCanonical.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[, deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.predict" title="sklearn.cross_decomposition.PLSCanonical.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, X[, copy])</p></td>
<td><p>Apply the dimension reduction learned on the train data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.score" title="sklearn.cross_decomposition.PLSCanonical.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(self, X, y[, sample_weight])</p></td>
<td><p>Returns the coefficient of determination R^2 of the prediction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.set_params" title="sklearn.cross_decomposition.PLSCanonical.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self, \*\*params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.cross_decomposition.PLSCanonical.transform" title="sklearn.cross_decomposition.PLSCanonical.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self, X[, Y, copy])</p></td>
<td><p>Apply the dimension reduction learned on the train data.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">n_components=2</em>, <em class="sig-param">scale=True</em>, <em class="sig-param">algorithm='nipals'</em>, <em class="sig-param">max_iter=500</em>, <em class="sig-param">tol=1e-06</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L744"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">Y</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L239"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples and
n_features is the number of predictors.</p>
</dd>
<dt><strong>Y</strong><span class="classifier">array-like, shape = [n_samples, n_targets]</span></dt><dd><p>Target vectors, where n_samples is the number of samples and
n_targets is the number of response variables.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L448"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn and apply the dimension reduction on the train data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples and
n_features is the number of predictors.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = [n_samples, n_targets]</span></dt><dd><p>Target vectors, where n_samples is the number of samples and
n_targets is the number of response variables.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>x_scores if Y is not given, (x_scores, y_scores) otherwise.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">deep=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/base.py#L169"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">boolean, optional</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">mapping of string to any</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L423"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the dimension reduction learned on the train data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples and
n_features is the number of predictors.</p>
</dd>
<dt><strong>copy</strong><span class="classifier">boolean, default True</span></dt><dd><p>Whether to copy X and Y, or perform in-place normalization.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This call requires the estimation of a p x q matrix, which may
be an issue in high dimensional space.</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">y</em>, <em class="sig-param">sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/base.py#L363"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = (n_samples, n_features)</span></dt><dd><p>Test samples. For some estimators this may be a
precomputed kernel matrix instead, shape = (n_samples,
n_samples_fitted], where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt><dd><p>True values for X.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like, shape = [n_samples], optional</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>R^2 of self.predict(X) wrt. y.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The R2 score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor will use
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>. This will influence the
<code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput regressors (except for
<a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>). To specify the
default value manually and avoid the warning, please either call
<a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> directly or make a custom scorer with
<a class="reference internal" href="sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> (the built-in scorer <code class="docutils literal notranslate"><span class="pre">'r2'</span></code> uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/base.py#L200"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>self</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="sklearn.cross_decomposition.PLSCanonical.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">Y=None</em>, <em class="sig-param">copy=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/743843d2c2/sklearn/cross_decomposition/pls_.py#L385"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.cross_decomposition.PLSCanonical.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the dimension reduction learned on the train data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>Training vectors, where n_samples is the number of samples and
n_features is the number of predictors.</p>
</dd>
<dt><strong>Y</strong><span class="classifier">array-like, shape = [n_samples, n_targets]</span></dt><dd><p>Target vectors, where n_samples is the number of samples and
n_targets is the number of response variables.</p>
</dd>
<dt><strong>copy</strong><span class="classifier">boolean, default True</span></dt><dd><p>Whether to copy X and Y, or perform in-place normalization.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>x_scores if Y is not given, (x_scores, y_scores) otherwise.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-sklearn-cross-decomposition-plscanonical">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">sklearn.cross_decomposition.PLSCanonical</span></code><a class="headerlink" href="#examples-using-sklearn-cross-decomposition-plscanonical" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Simple usage of various cross decomposition algorithms: - PLSCanonical - PLSRegression, with mu..."><div class="figure align-default" id="id1">
<img alt="../../_images/sphx_glr_plot_compare_cross_decomposition_thumb.png" src="../../_images/sphx_glr_plot_compare_cross_decomposition_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/cross_decomposition/plot_compare_cross_decomposition.html#sphx-glr-auto-examples-cross-decomposition-plot-compare-cross-decomposition-py"><span class="std std-ref">Compare cross decomposition methods</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="clearer"></div></div>
</div>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2019, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.cross_decomposition.PLSCanonical.rst.txt" rel="nofollow">Show this page source</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/jquery.min.js"></script>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>


<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Had navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        return target.getBoundingClientRect().top < 2;
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    if (hashTargetOnTop()) {
        navBar.style.top = navBarHeightHidden;
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        var currentScrollPos = window.pageYOffset;
        if (lastScrollTop > 2 && (prevScrollpos <= currentScrollPos) || hashTargetOnTop()){
            navBar.style.top = navBarHeightHidden;
        } else {
            navBar.style.top = "0";
        }
            prevScrollpos = currentScrollPos;
    };

    /*** high preformance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var $window = $(window);
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
<script>
    (function() {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
    })();
</script>
    
<script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    
</body>
</html>